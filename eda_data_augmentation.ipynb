{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\agarw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\agarw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\agarw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the training data:  7500\n",
      "The length of the testing data:  4500\n",
      "The length of the validation data:  3000\n"
     ]
    }
   ],
   "source": [
    "import ipynb.fs.full.preprocess_eda as preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can you walk me through setting up direct depo...</td>\n",
       "      <td>direct_deposit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i want to switch to direct deposit</td>\n",
       "      <td>direct_deposit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>set up direct deposit for me</td>\n",
       "      <td>direct_deposit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how do i go about setting up direct deposit</td>\n",
       "      <td>direct_deposit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i need to get my paycheck direct deposited to ...</td>\n",
       "      <td>direct_deposit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>i want my credit limit changed</td>\n",
       "      <td>credit_limit_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>i would like to increase my bank of america cr...</td>\n",
       "      <td>credit_limit_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>can i increase the credit limit on my old navy...</td>\n",
       "      <td>credit_limit_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>can i increase the credit limit on my kohls card</td>\n",
       "      <td>credit_limit_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>can i increase my credit limit to 700 dollars</td>\n",
       "      <td>credit_limit_change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Query               Intent\n",
       "0     can you walk me through setting up direct depo...       direct_deposit\n",
       "1                    i want to switch to direct deposit       direct_deposit\n",
       "2                          set up direct deposit for me       direct_deposit\n",
       "3           how do i go about setting up direct deposit       direct_deposit\n",
       "4     i need to get my paycheck direct deposited to ...       direct_deposit\n",
       "...                                                 ...                  ...\n",
       "7495                     i want my credit limit changed  credit_limit_change\n",
       "7496  i would like to increase my bank of america cr...  credit_limit_change\n",
       "7497  can i increase the credit limit on my old navy...  credit_limit_change\n",
       "7498   can i increase the credit limit on my kohls card  credit_limit_change\n",
       "7499      can i increase my credit limit to 700 dollars  credit_limit_change\n",
       "\n",
       "[7500 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess.train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_SR(original_text, n):\n",
    "    text = original_text.split().copy()\n",
    "    text_nonstopwords_index = []\n",
    "    for index, word in enumerate(text):\n",
    "        if word.lower() not in preprocess.STOPSWORD_ENG:\n",
    "            text_nonstopwords_index.append(index)\n",
    "    if not text_nonstopwords_index:\n",
    "            return original_text\n",
    "    if(n>len(text_nonstopwords_index)):\n",
    "            n = random.randint(0, int(len(text_nonstopwords_index)/2))\n",
    "    for i in range(n):\n",
    "        index = random.choice(text_nonstopwords_index)\n",
    "        text_nonstopwords_index.remove(index)\n",
    "        sysnoms = []\n",
    "        for synset in wordnet.synsets(text[index]):\n",
    "            for lemma in synset.lemmas():\n",
    "                if lemma.name() != text[index]:\n",
    "                    sysnoms.append(lemma.name())\n",
    "        if sysnoms == []:\n",
    "            continue\n",
    "        text[index] = random.choice(sysnoms).replace(\"_\", \" \")\n",
    "\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agumentated_df = preprocess.train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'set up lead bank for me'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda_SR(preprocess.train_df.iloc[2, 0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'set up direct deposit for me'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess.train_df.iloc[2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agumentated = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agumentated_query = []\n",
    "agumentated_intent = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agumentated_query.append(eda_SR(preprocess.train_df.iloc[2, 0], 2))\n",
    "agumentated_intent.append(preprocess.train_df.iloc[2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_RS(original_text, n):\n",
    "    text = original_text.split().copy()\n",
    "    index = [i for i in range(len(text))]\n",
    "    # if len(index) <= 1:\n",
    "    #     return original_text\n",
    "    # print(index)\n",
    "    # for i in range(n):\n",
    "    #    first_index = random.choice(index)\n",
    "    #    second_index = random.choice(index)\n",
    "    #    while(first_index == second_index):\n",
    "    #        second_index = random.choice(index)\n",
    "    #    text[first_index], text[second_index] = text[second_index], text[first_index]\n",
    "\n",
    "    while(len(index)>1 and n>0):\n",
    "        print(\"Index-->\", index, n)\n",
    "        n-=1\n",
    "        first_index = random.choice(index)\n",
    "        print(\"First Index\", first_index)\n",
    "        index.remove(first_index)\n",
    "        second_index = random.choice(index)\n",
    "        print(\"Second Index\", second_index)\n",
    "        index.remove(second_index)\n",
    "        text[first_index], text[second_index] = text[second_index], text[first_index]\n",
    "        \n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index--> [0, 1, 2, 3, 4] 6\n",
      "First Index 2\n",
      "Second Index 1\n",
      "Index--> [0, 3, 4] 5\n",
      "First Index 4\n",
      "Second Index 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'My is name Agarwal Mohit'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda_RS(\"My name is Mohit Agarwal\", 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_RD(original_text, p):\n",
    "    text = original_text.split().copy()\n",
    "    \n",
    "    if (p<=0 or p>=1) or len(text)<=1:\n",
    "        return original_text\n",
    "    for word in text:\n",
    "        word_probability = random.random()\n",
    "        print(word, word_probability)\n",
    "        if(word_probability <= p):\n",
    "            text.remove(word)\n",
    "    \n",
    "    if not text:\n",
    "        return original_text\n",
    "    \n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n"
     ]
    }
   ],
   "source": [
    "index = []\n",
    "if not index:\n",
    "    print(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My 0.7968863205579677\n",
      "is 0.2329002560645751\n",
      "Agarwal 0.9143757811497232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Name Mohit Agarwal'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda_RD(\"My Name is Mohit Agarwal\", 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_RI(original_text, n):\n",
    "    text = original_text.split().copy()\n",
    "    text_nonstopwords_index = []\n",
    "    for index, word in enumerate(text):\n",
    "        if word.lower() not in preprocess.STOPSWORD_ENG:\n",
    "            text_nonstopwords_index.append(index)\n",
    "    if(n>len(text_nonstopwords_index)):\n",
    "        n = random.randint(0, int(len(text_nonstopwords_index)/2))\n",
    "    for i in range(n):\n",
    "        index = random.choice(text_nonstopwords_index)\n",
    "        text_nonstopwords_index.remove(index)\n",
    "        sysnoms = []\n",
    "        for synset in wordnet.synsets(text[index]):\n",
    "            for lemma in synset.lemmas():\n",
    "                if lemma.name() != text[index]:\n",
    "                    sysnoms.append(lemma.name())\n",
    "        if sysnoms == []:\n",
    "            continue\n",
    "        text.insert(random.randint(0, len(text)-1), random.choice(sysnoms).replace(\"_\", \" \"))\n",
    "\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love to paly videogames'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda_RI(\"I love to paly videogames\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eda():\n",
    "    def find_nonstopwords_indices(self, text):\n",
    "        indices = []\n",
    "        for index, word in enumerate(text):\n",
    "            if word.lower() not in preprocess.STOPSWORD_ENG:\n",
    "                indices.append(index)\n",
    "        return indices\n",
    "    \n",
    "    def find_synonyms(self, word):\n",
    "        synonyms = []\n",
    "        for synset in wordnet.synsets(word):\n",
    "            for lemma in synset.lemmas():\n",
    "                if lemma.name() != word:\n",
    "                    synonyms.append(lemma.name())\n",
    "\n",
    "        return synonyms\n",
    "        \n",
    "    def eda_SR(self, original_text, n):\n",
    "        text = original_text.split().copy()\n",
    "        text_nonstopwords_indices = self.find_nonstopwords_indices(text=text)\n",
    "        \n",
    "        # checking if the text only have stopwords \n",
    "        if text_nonstopwords_indices == []:\n",
    "            return original_text\n",
    "        \n",
    "        if(n>len(text_nonstopwords_indices)):\n",
    "            n = random.randint(0, \n",
    "                               int(len(text_nonstopwords_indices)/2))\n",
    "\n",
    "        for i in range(n):\n",
    "            index = random.choice(text_nonstopwords_indices)\n",
    "            text_nonstopwords_indices.remove(index)\n",
    "            synonyms = self.find_synonyms(text[index])\n",
    "            if synonyms == []:\n",
    "                continue\n",
    "            text[index] = random.choice(synonyms).replace(\"_\", \" \")\n",
    "            if text_nonstopwords_indices == []:\n",
    "                break\n",
    "        return \" \".join(text)\n",
    "    \n",
    "    def eda_RI(self, original_text, n):\n",
    "        text = original_text.split().copy()\n",
    "        text_nonstopwords_indices = self.find_nonstopwords_indices(text=text)\n",
    "        \n",
    "        # checking if the text only have stopwords \n",
    "        if not text_nonstopwords_indices:\n",
    "            return original_text\n",
    "        \n",
    "        if(n>len(text_nonstopwords_indices)):\n",
    "            n = random.randint(0, \n",
    "                               int(len(text_nonstopwords_indices)/2))\n",
    "        for i in range(n):\n",
    "            index = random.choice(text_nonstopwords_indices)\n",
    "            text_nonstopwords_indices.remove(index)\n",
    "            synonyms = self.find_synonyms(text[index])\n",
    "            if synonyms == []:\n",
    "                continue\n",
    "            text.insert(random.randint(0, len(text)-1), \n",
    "                        random.choice(synonyms).replace(\"_\", \" \"))\n",
    "            if text_nonstopwords_indices == []:\n",
    "                break\n",
    "        return \" \".join(text)\n",
    "    \n",
    "    def eda_RD(self, original_text, p):\n",
    "        text = original_text.split().copy()\n",
    "    \n",
    "        if (p<=0 or p>=1) or len(text)<=1:\n",
    "            return original_text\n",
    "        \n",
    "        for word in text:\n",
    "            word_probability = random.random()\n",
    "            if(word_probability <= p):\n",
    "                text.remove(word)\n",
    "        \n",
    "        if not text:\n",
    "            return original_text\n",
    "        \n",
    "        return \" \".join(text)\n",
    "    \n",
    "    def eda_RS(self, original_text, n):\n",
    "        text = original_text.split().copy()\n",
    "        text_length = len(text)\n",
    "\n",
    "        for i in range(n):\n",
    "            first_index = random.randint(0, text_length-1)           \n",
    "            second_index = random.randint(0, text_length-1)       \n",
    "            while(second_index == first_index and text_length != 1):\n",
    "                second_index = random.randint(0, text_length-1)\n",
    "            text[first_index], text[second_index] = text[second_index], text[first_index]       \n",
    "            \n",
    "        return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class augment_data(eda):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        # self.augment_size = [1]\n",
    "        self.augment_size = [5, 10, 20, 30, 40, 50]\n",
    "        self.original_data = data\n",
    "        self.eda_methods = [\"SR\", \"RI\", \"RD\", \"RS\"]\n",
    "        self.augment_path = r\"D:\\MScDataScience\\7.Data_Science_Project\\SourceCode\\augment_data\"\n",
    "\n",
    "    def augment(self):\n",
    "        queries = self.original_data.iloc[:, 0].copy()\n",
    "        labels = self.original_data.iloc[:, 1].copy()\n",
    "\n",
    "        for size in self.augment_size:\n",
    "            augment_queries = []\n",
    "            # note - not augmenting labels, just to keep track\n",
    "            augment_labels = []\n",
    "            for i, query in enumerate(queries):\n",
    "                for j in range(size):\n",
    "                    augment_labels.append(labels[i])\n",
    "                    method = random.choice(self.eda_methods)\n",
    "                    # print(method)\n",
    "                    n = random.randint(0, len(query)-1)\n",
    "                    if method == \"SR\":\n",
    "                        augment_queries.append(super().eda_SR(query, n))\n",
    "                    elif method == \"RI\":\n",
    "                        augment_queries.append(super().eda_RI(query, n))\n",
    "                    elif method == \"RD\":\n",
    "                        augment_queries.append(super().eda_RD(query, random.random()))\n",
    "                    elif method == \"RS\":\n",
    "                        augment_queries.append(super().eda_RS(query, n))\n",
    "                # print(\"Length after every augment:\\n\", len(augment_queries), len(augment_labels))\n",
    "            # print(len(augment_queries), len(augment_labels))\n",
    "            preprocess.pd.DataFrame(\n",
    "                {\"Query\": augment_queries, \n",
    "                 \"Intent\": augment_labels}).\\\n",
    "                    to_csv(os.path.join(self.augment_path, \n",
    "                                        f\"eda_augmented_data_size_{size}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = augment_data(preprocess.train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment.augment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_sr = 0\n",
    "size_ri = 0\n",
    "size_rs = 0\n",
    "size_rd = 0\n",
    "for j in range(0, 2):\n",
    "    for i, query in enumerate(preprocess.train_df.iloc[:, 0]):\n",
    "        if eda_SR(query, 2):\n",
    "            size_sr+=1\n",
    "        if eda_RI(query, 2):\n",
    "            size_ri+=1\n",
    "        if eda_RS(query, 2):\n",
    "            size_rs+=1\n",
    "        if eda_RD(query, 0.2):\n",
    "            size_rd+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_obj = eda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000 150000 150000 150000\n"
     ]
    }
   ],
   "source": [
    "size_sr = 0\n",
    "size_ri = 0\n",
    "size_rs = 0\n",
    "size_rd = 0\n",
    "for j in range(0, 1):\n",
    "    for i, query in enumerate(preprocess.train_df.iloc[:, 0]):\n",
    "        if eda_obj.eda_SR(query, 2):\n",
    "            size_sr+=1\n",
    "        if eda_obj.eda_RI(query, 2):\n",
    "            size_ri+=1\n",
    "        if eda_obj.eda_RS(query, 2):\n",
    "            size_rs+=1\n",
    "        if eda_obj.eda_RD(query, 0.2):\n",
    "            size_rd+=1\n",
    "print(size_rd, size_ri, size_rs, size_sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
