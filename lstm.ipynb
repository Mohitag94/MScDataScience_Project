{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\agarw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\agarw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\agarw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the training data:  7500\n",
      "The length of the testing data:  4500\n",
      "The length of the validation data:  3000\n"
     ]
    }
   ],
   "source": [
    "import ipynb.fs.full.preprocess_eda as preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obj = preprocess.pre_process(preprocess.train_df)\n",
    "val_obj = preprocess.pre_process(preprocess.val_df)\n",
    "test_obj = preprocess.pre_process(preprocess.test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_obj.preprocess()\n",
    "x_train = train_obj.lemmatise()\n",
    "\n",
    "x_val = val_obj.preprocess()\n",
    "x_val = val_obj.lemmatise()\n",
    "\n",
    "x_test = test_obj.preprocess()\n",
    "x_test = test_obj.lemmatise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_obj.encode_class()\n",
    "y_val = val_obj.encode_class()\n",
    "y_test = test_obj.encode_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = y_train.shape[1]\n",
    "vocab_size = 50000\n",
    "text_seq_len = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "textvector_layer = keras.layers.TextVectorization(max_tokens=vocab_size, \n",
    "                                                  ngrams=(1, 2, 3),\n",
    "                                                  output_mode=\"int\", \n",
    "                                                  output_sequence_length=text_seq_len)\n",
    "textvector_layer.adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'need',\n",
       " 'please',\n",
       " 'card',\n",
       " 'tell',\n",
       " 'know',\n",
       " 'get',\n",
       " 'credit',\n",
       " 'account',\n",
       " 'want',\n",
       " 'would',\n",
       " 'car',\n",
       " 'list',\n",
       " 'like',\n",
       " 'change',\n",
       " 'time',\n",
       " 'go',\n",
       " 'bank',\n",
       " 'new',\n",
       " 'many',\n",
       " 'bill',\n",
       " 'would like',\n",
       " 'make',\n",
       " 'reservation',\n",
       " 'much',\n",
       " 'day',\n",
       " 'take',\n",
       " 'credit card',\n",
       " 'find',\n",
       " 'name',\n",
       " 'help',\n",
       " 'long',\n",
       " 'next',\n",
       " 'visa',\n",
       " 'oil',\n",
       " 'set',\n",
       " 'let',\n",
       " 'use',\n",
       " 'check',\n",
       " 'pay',\n",
       " 'flight',\n",
       " 'date',\n",
       " 'phone',\n",
       " 'song',\n",
       " 'shopping',\n",
       " 'tire',\n",
       " 'need know',\n",
       " 'vacation',\n",
       " 'number',\n",
       " 'good',\n",
       " 'last',\n",
       " 'call',\n",
       " 'one',\n",
       " 'meeting',\n",
       " 'add',\n",
       " 'shopping list',\n",
       " 'going',\n",
       " 'order',\n",
       " 'current',\n",
       " 'march',\n",
       " 'give',\n",
       " 'put',\n",
       " 'limit',\n",
       " 'gas',\n",
       " 'today',\n",
       " 'travel',\n",
       " 'transaction',\n",
       " 'request',\n",
       " 'insurance',\n",
       " 'could',\n",
       " 'score',\n",
       " 'playlist',\n",
       " 'calendar',\n",
       " 'credit score',\n",
       " 'tax',\n",
       " 'say',\n",
       " 'report',\n",
       " 'point',\n",
       " 'reminder',\n",
       " 'right',\n",
       " 'thing',\n",
       " 'way',\n",
       " 'schedule',\n",
       " 'location',\n",
       " 'credit limit',\n",
       " 'ai',\n",
       " 'rate',\n",
       " 'kind',\n",
       " 'bank account',\n",
       " 'dollar',\n",
       " 'let know',\n",
       " 'pm',\n",
       " 'lost',\n",
       " 'setting',\n",
       " 'see',\n",
       " 'chase',\n",
       " 'look',\n",
       " 'work',\n",
       " 'pto',\n",
       " 'place',\n",
       " 'status',\n",
       " 'checking',\n",
       " 'start',\n",
       " 'amount',\n",
       " 'visa card',\n",
       " 'got',\n",
       " 'saving',\n",
       " 'reward',\n",
       " 'plan',\n",
       " 'payment',\n",
       " 'money',\n",
       " 'life',\n",
       " 'timezone',\n",
       " 'routing number',\n",
       " 'routing',\n",
       " 'hear',\n",
       " 'apr',\n",
       " 'uber',\n",
       " 'text',\n",
       " 'roll',\n",
       " 'pin',\n",
       " 'month',\n",
       " 'direct',\n",
       " 'traffic',\n",
       " 'restaurant',\n",
       " 'play',\n",
       " 'interest',\n",
       " 'due',\n",
       " 'dinner',\n",
       " 'changed',\n",
       " 'calorie',\n",
       " 'alarm',\n",
       " 'type',\n",
       " 'please tell',\n",
       " 'meaning',\n",
       " 'change oil',\n",
       " 'voice',\n",
       " 'show',\n",
       " 'review',\n",
       " 'luggage',\n",
       " 'interest rate',\n",
       " 'cancel',\n",
       " 'tomorrow',\n",
       " 'timer',\n",
       " 'deposit',\n",
       " 'application',\n",
       " 'volume',\n",
       " 'vacation day',\n",
       " 'increase',\n",
       " 'paycheck',\n",
       " 'direct deposit',\n",
       " 'coin',\n",
       " 'balance',\n",
       " 'made',\n",
       " 'book',\n",
       " 'america',\n",
       " 'year',\n",
       " 'send',\n",
       " 'dice',\n",
       " 'alert',\n",
       " 'would like know',\n",
       " 'whisper',\n",
       " 'want know',\n",
       " 'turn',\n",
       " 'people',\n",
       " 'like know',\n",
       " 'flip',\n",
       " 'fact',\n",
       " 'confirm',\n",
       " 'bank america',\n",
       " 'stop',\n",
       " 'long take',\n",
       " 'hotel',\n",
       " 'fun',\n",
       " 'cannot',\n",
       " 'think',\n",
       " 'table',\n",
       " 'room',\n",
       " 'jump',\n",
       " 'declined',\n",
       " 'u',\n",
       " 'switch',\n",
       " 'red',\n",
       " 'minimum',\n",
       " 'may',\n",
       " 'fuel',\n",
       " 'someone',\n",
       " 'pizza',\n",
       " 'oil change',\n",
       " 'fee',\n",
       " 'apply',\n",
       " 'transfer',\n",
       " 'something',\n",
       " 'recipe',\n",
       " 'pet',\n",
       " 'meaning life',\n",
       " 'left',\n",
       " 'delta',\n",
       " 'chicken',\n",
       " 'stolen',\n",
       " 'saving account',\n",
       " 'possible',\n",
       " 'confirm reservation',\n",
       " 'buy',\n",
       " 'american',\n",
       " 'used',\n",
       " 'travel alert',\n",
       " 'share',\n",
       " 'person',\n",
       " 'checking account',\n",
       " 'water',\n",
       " 'speak',\n",
       " 'soon',\n",
       " 'milk',\n",
       " 'mastercard',\n",
       " 'factory',\n",
       " 'carry',\n",
       " 'back',\n",
       " 'answer',\n",
       " 'another',\n",
       " 'week',\n",
       " 'using',\n",
       " 'take reservation',\n",
       " 'spell',\n",
       " 'rent',\n",
       " 'plug',\n",
       " 'need get',\n",
       " 'minute',\n",
       " 'food',\n",
       " 'april',\n",
       " 'shot',\n",
       " 'scheduled',\n",
       " 'pto request',\n",
       " 'new card',\n",
       " 'light',\n",
       " 'ingredient',\n",
       " 'card point',\n",
       " 'bus',\n",
       " 'talk',\n",
       " 'monday',\n",
       " 'mode',\n",
       " 'discover',\n",
       " 'total',\n",
       " 'schedule meeting',\n",
       " 'must',\n",
       " 'many vacation',\n",
       " 'male',\n",
       " 'let u',\n",
       " 'get new',\n",
       " 'fridge',\n",
       " 'french',\n",
       " 'fraudulent',\n",
       " 'air',\n",
       " 'take get',\n",
       " 'robin',\n",
       " 'replace',\n",
       " 'repeat',\n",
       " 'red robin',\n",
       " 'paid',\n",
       " 'need report',\n",
       " 'need help',\n",
       " 'many vacation day',\n",
       " 'job',\n",
       " 'form',\n",
       " 'factory setting',\n",
       " 'everything',\n",
       " 'credit card point',\n",
       " 'yesterday',\n",
       " 'whisper mode',\n",
       " 'todo list',\n",
       " 'todo',\n",
       " 'set direct',\n",
       " 'read',\n",
       " 'rating',\n",
       " 'pressure',\n",
       " 'pin number',\n",
       " 'need change',\n",
       " 'mpg',\n",
       " 'jump start',\n",
       " 'joke',\n",
       " 'international',\n",
       " 'insurance plan',\n",
       " 'information',\n",
       " 'inform',\n",
       " 'hobby',\n",
       " 'cat',\n",
       " 'busy',\n",
       " 'benefit',\n",
       " 'appointment',\n",
       " 'able',\n",
       " 'true',\n",
       " 'state',\n",
       " 'set direct deposit',\n",
       " 'rental',\n",
       " 'mile',\n",
       " 'language',\n",
       " 'health',\n",
       " 'currently',\n",
       " 'cook',\n",
       " 'city',\n",
       " 'cancel reservation',\n",
       " 'available',\n",
       " 'amex',\n",
       " 'ahead',\n",
       " 'vacation request',\n",
       " 'transaction fee',\n",
       " 'sure',\n",
       " 'since',\n",
       " 'sided',\n",
       " 'remove',\n",
       " 'new credit card',\n",
       " 'new credit',\n",
       " 'mexico',\n",
       " 'mean',\n",
       " 'increase credit limit',\n",
       " 'increase credit',\n",
       " 'hold',\n",
       " 'hello',\n",
       " 'go ahead',\n",
       " 'exchange',\n",
       " 'dog',\n",
       " 'discover card',\n",
       " 'card application',\n",
       " 'bad',\n",
       " 'airline',\n",
       " 'yet',\n",
       " 'remind',\n",
       " 'remember',\n",
       " 'minimum payment',\n",
       " 'make reservation',\n",
       " 'income',\n",
       " 'home',\n",
       " 'help find',\n",
       " 'gps',\n",
       " 'funny',\n",
       " 'flip coin',\n",
       " 'electric',\n",
       " 'current location',\n",
       " 'cream',\n",
       " 'converter',\n",
       " 'chicago',\n",
       " 'change pin',\n",
       " 'york',\n",
       " 'wait',\n",
       " 'trip',\n",
       " 'talking',\n",
       " 'spend',\n",
       " 'reminder list',\n",
       " 'next song',\n",
       " 'new york',\n",
       " 'meal',\n",
       " 'many day',\n",
       " 'la',\n",
       " 'info',\n",
       " 'garden',\n",
       " 'expect',\n",
       " 'electric bill',\n",
       " 'credit card application',\n",
       " 'company',\n",
       " 'change name',\n",
       " 'battery',\n",
       " 'around',\n",
       " 'activity',\n",
       " 'yen',\n",
       " 'weather',\n",
       " 'tuesday',\n",
       " 'spent',\n",
       " 'spending',\n",
       " 'spanish',\n",
       " 'shop',\n",
       " 'playing',\n",
       " 'olive',\n",
       " 'nutritional',\n",
       " 'locate',\n",
       " 'instead',\n",
       " 'gps coordinate',\n",
       " 'express',\n",
       " 'coordinate',\n",
       " 'card declined',\n",
       " 'approved',\n",
       " 'american express',\n",
       " 'word',\n",
       " 'two',\n",
       " 'thank',\n",
       " 'set alarm',\n",
       " 'safe',\n",
       " 'rollover',\n",
       " 'roll dice',\n",
       " 'reset',\n",
       " 'reserve',\n",
       " 'real',\n",
       " 'oil changed',\n",
       " 'item',\n",
       " 'inch',\n",
       " 'holiday',\n",
       " 'good review',\n",
       " 'frozen',\n",
       " 'february',\n",
       " 'enough',\n",
       " 'eat',\n",
       " 'checkbook',\n",
       " 'chase account',\n",
       " 'ask',\n",
       " 'airport',\n",
       " 'water bill',\n",
       " 'traveling',\n",
       " 'traffic like',\n",
       " 'suggest',\n",
       " 'start car',\n",
       " 'slow',\n",
       " 'set timer',\n",
       " 'rent car',\n",
       " 'order check',\n",
       " 'old',\n",
       " 'many calorie',\n",
       " 'lot',\n",
       " 'fun fact',\n",
       " 'expire',\n",
       " 'create',\n",
       " 'charge',\n",
       " 'carryon',\n",
       " 'accent',\n",
       " 'well',\n",
       " 'suggestion',\n",
       " 'set reminder',\n",
       " 'saved',\n",
       " 'reservation pm',\n",
       " 'redeem',\n",
       " 'play next',\n",
       " 'owe',\n",
       " 'olive garden',\n",
       " 'oil car',\n",
       " 'nutrition',\n",
       " 'next paycheck',\n",
       " 'next day',\n",
       " 'new insurance',\n",
       " 'need visa',\n",
       " 'near',\n",
       " 'france',\n",
       " 'engine',\n",
       " 'country',\n",
       " 'convert',\n",
       " 'come',\n",
       " 'card stolen',\n",
       " 'card got',\n",
       " 'card apr',\n",
       " 'called',\n",
       " 'united',\n",
       " 'trivia',\n",
       " 'thanks',\n",
       " 'tell something',\n",
       " 'step',\n",
       " 'something funny',\n",
       " 'sided dice',\n",
       " 'rental car',\n",
       " 'recent',\n",
       " 'package',\n",
       " 'need make',\n",
       " 'music',\n",
       " 'meeting room',\n",
       " 'long take get',\n",
       " 'keep',\n",
       " 'high',\n",
       " 'go back',\n",
       " 'getting',\n",
       " 'first',\n",
       " 'female',\n",
       " 'engine light',\n",
       " 'dallas',\n",
       " 'chase card',\n",
       " 'change oil car',\n",
       " 'cable bill',\n",
       " 'cable',\n",
       " 'born',\n",
       " 'best',\n",
       " 'yes',\n",
       " 'walk',\n",
       " 'update',\n",
       " 'travelling',\n",
       " 'tonight',\n",
       " 'tell bank',\n",
       " 'tank',\n",
       " 'tail',\n",
       " 'replaced',\n",
       " 'refer',\n",
       " 'really',\n",
       " 'policy',\n",
       " 'please find',\n",
       " 'pay tax',\n",
       " 'ons',\n",
       " 'need new',\n",
       " 'love',\n",
       " 'list please',\n",
       " 'let bank',\n",
       " 'june',\n",
       " 'jump start car',\n",
       " 'get oil',\n",
       " 'friday',\n",
       " 'female voice',\n",
       " 'definition',\n",
       " 'could tell',\n",
       " 'correct',\n",
       " 'content',\n",
       " 'chili',\n",
       " 'carry ons',\n",
       " 'car battery',\n",
       " 'bill due',\n",
       " 'bank know',\n",
       " 'would say',\n",
       " 'vega',\n",
       " 'use card',\n",
       " 'tire pressure',\n",
       " 'tell credit',\n",
       " 'sugar',\n",
       " 'sort',\n",
       " 'socket converter',\n",
       " 'socket',\n",
       " 'reward point',\n",
       " 'report card',\n",
       " 'recently',\n",
       " 'process',\n",
       " 'pound',\n",
       " 'please help',\n",
       " 'please give',\n",
       " 'play song',\n",
       " 'pie',\n",
       " 'needed',\n",
       " 'march march',\n",
       " 'many mile',\n",
       " 'male voice',\n",
       " 'maintenance',\n",
       " 'looking',\n",
       " 'list add',\n",
       " 'let bank know',\n",
       " 'later',\n",
       " 'land',\n",
       " 'january',\n",
       " 'italian',\n",
       " 'instruction',\n",
       " 'inform bank',\n",
       " 'human',\n",
       " 'hey',\n",
       " 'head',\n",
       " 'figure',\n",
       " 'federal',\n",
       " 'express card',\n",
       " 'expires',\n",
       " 'event',\n",
       " 'delta flight',\n",
       " 'check engine light',\n",
       " 'check engine',\n",
       " 'cash',\n",
       " 'canada',\n",
       " 'british',\n",
       " 'arrive',\n",
       " 'apple',\n",
       " 'anything',\n",
       " 'american express card',\n",
       " 'well fargo',\n",
       " 'want hear',\n",
       " 'visa go',\n",
       " 'track',\n",
       " 'task',\n",
       " 'taken',\n",
       " 'swap',\n",
       " 'state tax',\n",
       " 'starbucks',\n",
       " 'seattle',\n",
       " 'said',\n",
       " 'russia',\n",
       " 'reserve table',\n",
       " 'replacement',\n",
       " 'real person',\n",
       " 'question',\n",
       " 'please add',\n",
       " 'pay bill',\n",
       " 'office',\n",
       " 'need pay',\n",
       " 'much money',\n",
       " 'mom',\n",
       " 'low',\n",
       " 'lost luggage',\n",
       " 'level',\n",
       " 'leave',\n",
       " 'idea',\n",
       " 'good place',\n",
       " 'get uber',\n",
       " 'gas car',\n",
       " 'freeze',\n",
       " 'fargo',\n",
       " 'far',\n",
       " 'disconnect',\n",
       " 'different',\n",
       " 'dead',\n",
       " 'damaged',\n",
       " 'credit rating',\n",
       " 'computer',\n",
       " 'change pin number',\n",
       " 'car get',\n",
       " 'capital one',\n",
       " 'capital',\n",
       " 'calling',\n",
       " 'cake',\n",
       " 'august',\n",
       " 'amex card',\n",
       " 'zone',\n",
       " 'walmart',\n",
       " 'w',\n",
       " 'vehicle',\n",
       " 'vaccination',\n",
       " 'translate',\n",
       " 'traffic like way',\n",
       " 'today date',\n",
       " 'time zone',\n",
       " 'ten',\n",
       " 'speech',\n",
       " 'song playlist',\n",
       " 'send text',\n",
       " 'returning',\n",
       " 'restriction',\n",
       " 'required',\n",
       " 'reason',\n",
       " 'raise',\n",
       " 'purchase',\n",
       " 'please let',\n",
       " 'please change',\n",
       " 'peso',\n",
       " 'pay electric bill',\n",
       " 'pay electric',\n",
       " 'outback',\n",
       " 'original',\n",
       " 'noon',\n",
       " 'new job',\n",
       " 'need uber',\n",
       " 'miami',\n",
       " 'mall',\n",
       " 'limit visa',\n",
       " 'like way',\n",
       " 'lately',\n",
       " 'know much',\n",
       " 'john',\n",
       " 'italy',\n",
       " 'international visa',\n",
       " 'house',\n",
       " 'hotel room',\n",
       " 'grocery',\n",
       " 'get tire',\n",
       " 'fraudulent transaction',\n",
       " 'false',\n",
       " 'exchange rate',\n",
       " 'dish',\n",
       " 'disconnect phone',\n",
       " 'delete',\n",
       " 'day request',\n",
       " 'connect',\n",
       " 'coin flip',\n",
       " 'chris',\n",
       " 'charged',\n",
       " 'changing',\n",
       " 'cat dog',\n",
       " 'card expires',\n",
       " 'calendar march',\n",
       " 'block',\n",
       " 'account frozen',\n",
       " 'x',\n",
       " 'use credit card',\n",
       " 'use credit',\n",
       " 'tourist',\n",
       " 'tire changed',\n",
       " 'text message',\n",
       " 'temperature',\n",
       " 'tell current',\n",
       " 'tampa',\n",
       " 'sushi',\n",
       " 'substitute',\n",
       " 'station',\n",
       " 'speed',\n",
       " 'speaking',\n",
       " 'spain',\n",
       " 'south',\n",
       " 'salary',\n",
       " 'reservation red',\n",
       " 'request march',\n",
       " 'report lost',\n",
       " 'recent transaction',\n",
       " 'ran',\n",
       " 'pto request march',\n",
       " 'processed',\n",
       " 'potato',\n",
       " 'please set',\n",
       " 'please cancel',\n",
       " 'placed',\n",
       " 'phone please',\n",
       " 'phoenix',\n",
       " 'pay cable bill',\n",
       " 'pay cable',\n",
       " 'pair',\n",
       " 'online',\n",
       " 'okay',\n",
       " 'nutritional info',\n",
       " 'new one',\n",
       " 'need find',\n",
       " 'nearest',\n",
       " 'much time',\n",
       " 'message',\n",
       " 'make sure',\n",
       " 'mailed',\n",
       " 'mail',\n",
       " 'live',\n",
       " 'last time',\n",
       " 'know credit',\n",
       " 'kind gas',\n",
       " 'insurance policy',\n",
       " 'ice',\n",
       " 'houston',\n",
       " 'help get',\n",
       " 'health plan',\n",
       " 'go bad',\n",
       " 'get table',\n",
       " 'get oil changed',\n",
       " 'germany',\n",
       " 'gas tank',\n",
       " 'gas need',\n",
       " 'foot',\n",
       " 'find recipe',\n",
       " 'expiration date',\n",
       " 'expiration',\n",
       " 'exactly',\n",
       " 'everything shopping',\n",
       " 'else',\n",
       " 'egg',\n",
       " 'door',\n",
       " 'doctor',\n",
       " 'closest',\n",
       " 'cleaning',\n",
       " 'change tire',\n",
       " 'change language',\n",
       " 'carryon restriction',\n",
       " 'boston',\n",
       " 'bob',\n",
       " 'assistance',\n",
       " 'applebees',\n",
       " 'want change',\n",
       " 'visit',\n",
       " 'vacation time',\n",
       " 'type gas',\n",
       " 'tell something funny',\n",
       " 'tell date',\n",
       " 'still',\n",
       " 'specific',\n",
       " 'soon want',\n",
       " 'song playing',\n",
       " 'slower',\n",
       " 'shopping list add',\n",
       " 'share location',\n",
       " 'rule',\n",
       " 'roll sided dice',\n",
       " 'roll sided',\n",
       " 'response',\n",
       " 'reservation red robin',\n",
       " 'require',\n",
       " 'provide',\n",
       " 'pork',\n",
       " 'please repeat',\n",
       " 'paying',\n",
       " 'one account',\n",
       " 'next song playlist',\n",
       " 'next holiday',\n",
       " 'needing',\n",
       " 'name use',\n",
       " 'mpg car',\n",
       " 'minute timer',\n",
       " 'meeting today',\n",
       " 'meeting scheduled',\n",
       " 'market',\n",
       " 'many carry ons',\n",
       " 'many carry',\n",
       " 'make reminder',\n",
       " 'macaroni',\n",
       " 'looked',\n",
       " 'longer',\n",
       " 'lobster',\n",
       " 'latest',\n",
       " 'know spell',\n",
       " 'japan',\n",
       " 'international transaction',\n",
       " 'ingredient need',\n",
       " 'increase volume',\n",
       " 'ice cream',\n",
       " 'hi',\n",
       " 'great',\n",
       " 'got declined',\n",
       " 'german',\n",
       " 'gas bill',\n",
       " 'free',\n",
       " 'five',\n",
       " 'find phone',\n",
       " 'everything shopping list',\n",
       " 'enjoy',\n",
       " 'either',\n",
       " 'due date',\n",
       " 'declined yesterday',\n",
       " 'credit card apr',\n",
       " 'coming',\n",
       " 'cheese',\n",
       " 'card got declined',\n",
       " 'car shop',\n",
       " 'bread',\n",
       " 'bos',\n",
       " 'book flight',\n",
       " 'beef',\n",
       " 'back factory setting',\n",
       " 'back factory',\n",
       " 'baby',\n",
       " 'away',\n",
       " 'aware',\n",
       " 'auto',\n",
       " 'amazon',\n",
       " 'already',\n",
       " 'air tire',\n",
       " 'working',\n",
       " 'want inform bank',\n",
       " 'want inform',\n",
       " 'using card',\n",
       " 'trying',\n",
       " 'try',\n",
       " 'travel alert aware',\n",
       " 'tell status',\n",
       " 'tell many',\n",
       " 'target',\n",
       " 'switch whisper',\n",
       " 'suggest meal',\n",
       " 'stop bank account',\n",
       " 'stop bank',\n",
       " 'steakhouse',\n",
       " 'status credit card',\n",
       " 'status credit',\n",
       " 'soda',\n",
       " 'seems',\n",
       " 'saturday',\n",
       " 'san',\n",
       " 'salt',\n",
       " 'roundtrip flight',\n",
       " 'roundtrip',\n",
       " 'reset factory setting',\n",
       " 'reset factory',\n",
       " 'report fraudulent',\n",
       " 'replacement card',\n",
       " 'red lobster',\n",
       " 'receive',\n",
       " 'put pto request',\n",
       " 'put pto',\n",
       " 'please make',\n",
       " 'please confirm',\n",
       " 'per',\n",
       " 'original setting',\n",
       " 'order checkbook',\n",
       " 'option',\n",
       " 'nice',\n",
       " 'need set',\n",
       " 'need international visa',\n",
       " 'need international',\n",
       " 'name saved',\n",
       " 'much spent',\n",
       " 'much spend',\n",
       " 'much pay',\n",
       " 'many point',\n",
       " 'lost card',\n",
       " 'long cook',\n",
       " 'list reminder',\n",
       " 'laundry',\n",
       " 'last month',\n",
       " 'la vega',\n",
       " 'know name',\n",
       " 'know long',\n",
       " 'know get',\n",
       " 'kevin',\n",
       " 'interesting',\n",
       " 'insurance benefit',\n",
       " 'improve credit',\n",
       " 'improve',\n",
       " 'healthy',\n",
       " 'half',\n",
       " 'get tire changed',\n",
       " 'get checkbook',\n",
       " 'gallon',\n",
       " 'friend',\n",
       " 'freezer',\n",
       " 'fraudulent activity',\n",
       " 'find routing number',\n",
       " 'find routing',\n",
       " 'federal tax',\n",
       " 'favorite',\n",
       " 'fan',\n",
       " 'explain',\n",
       " 'euro',\n",
       " 'earned',\n",
       " 'day used',\n",
       " 'day left',\n",
       " 'date last',\n",
       " 'date credit card',\n",
       " 'date credit',\n",
       " 'current time',\n",
       " 'connect phone',\n",
       " 'china',\n",
       " 'chase bank',\n",
       " 'changing oil',\n",
       " 'centimeter',\n",
       " 'card get',\n",
       " 'card expire',\n",
       " 'card declined yesterday',\n",
       " 'car need',\n",
       " 'bring',\n",
       " 'birthday',\n",
       " 'bag',\n",
       " 'b',\n",
       " 'amount pay',\n",
       " 'allow',\n",
       " 'alert aware',\n",
       " 'would tell',\n",
       " 'whisper voice',\n",
       " 'whether',\n",
       " 'wednesday',\n",
       " 'time flight',\n",
       " 'tell name',\n",
       " 'tell much',\n",
       " 'switch whisper mode',\n",
       " 'steve',\n",
       " 'stay',\n",
       " 'square',\n",
       " 'spending lot',\n",
       " 'spaghetti',\n",
       " 'southwest',\n",
       " 'sour cream',\n",
       " 'sour',\n",
       " 'soon want inform',\n",
       " 'show transaction',\n",
       " 'shoe',\n",
       " 'search',\n",
       " 'schedule car',\n",
       " 'ruble',\n",
       " 'rock',\n",
       " 'right away',\n",
       " 'rid',\n",
       " 'reservation pm red',\n",
       " 'remaining',\n",
       " 'pto used',\n",
       " 'pm red robin',\n",
       " 'pm red',\n",
       " 'please look',\n",
       " 'phone bill',\n",
       " 'ounce',\n",
       " 'orlando',\n",
       " 'ordered',\n",
       " 'need socket converter',\n",
       " 'need socket',\n",
       " 'need replace',\n",
       " 'nashville',\n",
       " 'much pto',\n",
       " 'move',\n",
       " 'money market',\n",
       " 'mind',\n",
       " 'meeting schedule',\n",
       " 'mcdonalds',\n",
       " 'map',\n",
       " 'many reward',\n",
       " 'making',\n",
       " 'lower',\n",
       " 'look like',\n",
       " 'listening',\n",
       " 'list thing',\n",
       " 'list shopping',\n",
       " 'liberty',\n",
       " 'learn',\n",
       " 'july',\n",
       " 'job need',\n",
       " 'international transaction fee',\n",
       " 'improve credit score',\n",
       " 'hour',\n",
       " 'highway',\n",
       " 'good rating',\n",
       " 'get rid',\n",
       " 'fry',\n",
       " 'fridge since',\n",
       " 'fill',\n",
       " 'event calendar',\n",
       " 'english',\n",
       " 'england',\n",
       " 'drive',\n",
       " 'doo',\n",
       " 'die',\n",
       " 'delivered',\n",
       " 'count',\n",
       " 'choose',\n",
       " 'chocolate',\n",
       " 'chinese',\n",
       " 'checked',\n",
       " 'check see',\n",
       " 'car maintenance',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textvector_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class models():\n",
    "    def __init__(self, num_class, vocab_size, embedding_seq_length, \n",
    "                 textvector_layer=textvector_layer):\n",
    "        # self.hp = hp\n",
    "        self.num_class = num_class \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_seq_length = embedding_seq_length\n",
    "        self.textvector_layer = textvector_layer\n",
    "\n",
    "    def base_layer(self):\n",
    "        model = Sequential()\n",
    "        model.add(self.textvector_layer)\n",
    "        model.add(keras.layers.Embedding(self.vocab_size+2,\n",
    "                                         self.embedding_seq_length,\n",
    "                                         trainable=\"True\"))\n",
    "        return model\n",
    "    \n",
    "    def top_layer(self, model):\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(self.num_class, activation=\"softmax\"))\n",
    "    \n",
    "    def single_lstm(self, lstm_units, rate, activation):\n",
    "        model = self.base_layer()\n",
    "        model.add(keras.layers.LSTM(lstm_units, \n",
    "                       dropout=rate,\n",
    "                       recurrent_dropout=rate,\n",
    "                       activation=activation))\n",
    "        self.top_layer(model=model)\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def stacked_lstm(self, lstm_units1, lstm_units2, activation, \n",
    "                     rate1=0.2, rate2=0.2):\n",
    "        model = self.base_layer()\n",
    "\n",
    "        model.add(keras.layers.LSTM(lstm_units1,\n",
    "                                    activation=activation,\n",
    "                                    dropout=rate1,\n",
    "                                    recurrent_dropout=rate1,\n",
    "                                    return_sequences=True))\n",
    "\n",
    "        model.add(keras.layers.LSTM(lstm_units2,\n",
    "                                    activation=activation,\n",
    "                                    dropout=rate2,\n",
    "                                    recurrent_dropout=rate2))\n",
    "        self.top_layer(model=model)\n",
    "\n",
    "    def convo_lstm(self, convo_units, kernal_size, convo_rate, convo_activaton,\n",
    "                   lstm_units, lstm_rate, lstm_activation):\n",
    "        model = self.base_layer()\n",
    "\n",
    "        model.add(keras.layers.Conv1D(units=convo_units, \n",
    "                                      kernal_size=kernal_size,\n",
    "                                      activation=convo_activaton,\n",
    "                                      padding=\"same\"))\n",
    "        model.dropout(convo_rate)\n",
    "        model.add(keras.layers.LSTM(lstm_units,\n",
    "                                    dropout=lstm_rate,\n",
    "                                    recurrent_dropout=lstm_rate,\n",
    "                                    activation=lstm_activation))\n",
    "        self.top_layer(model=model)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class hyper_model(keras_tuner.HyperModel):\n",
    "#         def build(self, hp):\n",
    "#             lstm = models(num_class=num_class, \n",
    "#                            vocab_size=vocab_size, \n",
    "#                            embedding_seq_length=hp.Int(\"embedding_seq_length\", \n",
    "#                                                        min_value=10, \n",
    "#                                                        max_value=150, \n",
    "#                                                        step=10))\n",
    "            \n",
    "#             activations = [\"relu\", \"tanh\", \"sigmoid\",\n",
    "#                            \"elu\", \"exponential\", \"selu\"]\n",
    "            \n",
    "                                \n",
    "#             which_model = hp.Choice(\"which_model\",\n",
    "#                                     values=[\"stacked_lstm\", \n",
    "#                                             \"convo_lstm\",\n",
    "#                                             \"single_lstm\"])\n",
    "#             if(which_model == \"single_lstm\"):\n",
    "#                   model = lstm.single_lstm(lstm_units=hp.Int(\"lstm_units\", \n",
    "#                                                              min_value=25, \n",
    "#                                                              max_value=200, \n",
    "#                                                              step=5), \n",
    "#                                            rate=hp.Float(\"rate\", \n",
    "#                                                          min_value=0.2,\n",
    "#                                                          max_value=0.7, \n",
    "#                                                          step=0.025),\n",
    "#                                            activation=hp.Choice(\"activation\", \n",
    "#                                                                 values=activations))\n",
    "\n",
    "#             elif(which_model == \"stacked_lstm\"):\n",
    "#                   model = lstm.stacked_lstm(lstm_units1=hp.Int(\"lstm_units1\", \n",
    "#                                                              min_value=25, \n",
    "#                                                              max_value=200, \n",
    "#                                                              step=5),\n",
    "#                                              lstm_units2=hp.Int(\"lstm_units2\", \n",
    "#                                                              min_value=25, \n",
    "#                                                              max_value=200, \n",
    "#                                                              step=5),\n",
    "#                                              rate1=hp.Float(\"rate1\", \n",
    "#                                                          min_value=0.2,\n",
    "#                                                          max_value=0.7, \n",
    "#                                                          step=0.025),\n",
    "#                                              rate2=hp.Float(\"rate2\", \n",
    "#                                                          min_value=0.2,\n",
    "#                                                          max_value=0.7, \n",
    "#                                                          step=0.025),\n",
    "#                                            activation=hp.Choice(\"activation\", \n",
    "#                                                                 values=activations))\n",
    "                  \n",
    "#             elif(which_model == \"convo_lstm\"):\n",
    "#                   convo_units = hp.Int(\"convo_uints\", min_value=32, \n",
    "#                                        max_value=512, step=32)\n",
    "#                   kernal_size = hp.Int(\"kernal_size\", min_value=2, \n",
    "#                                        max_value=6, step=1)\n",
    "#                   convo_rate = hp.Float(\"convo_rate\", min_value=0.2, \n",
    "#                                         max_value=0.7, step=0.025)\n",
    "#                   convo_activaton = hp.Choice(\"convo_activation\", values=activations)\n",
    "#                   lstm_units = hp.Int(\"lstm_units\", min_value=25, \n",
    "#                                       max_value=200, step=5)\n",
    "#                   lstm_rate = hp.Float(\"lstm_rate\", min_value=0.2, \n",
    "#                                         max_value=0.7, step=0.025)\n",
    "#                   lstm_activation = hp.Choice(\"lstm_activation\", values=activations)\n",
    "\n",
    "#                   model = lstm.convo_lstm(convo_units=convo_units, kernal_size=kernal_size, convo_rate=convo_rate,\n",
    "#                                           convo_activaton=convo_activaton, lstm_units=lstm_units, lstm_rate=lstm_rate, \n",
    "#                                           lstm_activation=lstm_activation)\n",
    "\n",
    "#             lr = hp.Float(\"learning_rate\", min_value=0.001, \n",
    "#                           max_value=0.02, sampling=\"log\")\n",
    "            \n",
    "#             optimizer_dict = {\n",
    "#                   \"SGD\" : keras.optimizers.SGD(lr),\n",
    "#                   \"Adam\" : keras.optimizers.Adam(lr),\n",
    "#                   \"Nadam\" : keras.optimizers.Nadam(lr),\n",
    "#                   \"Adamax\" : keras.optimizers.Adamax(lr),\n",
    "#                   \"RMSprop\" : keras.optimizers.RMSprop(lr)\n",
    "#             }\n",
    "\n",
    "#             optimizer = hp.Choice(\"optimizer\", \n",
    "#                                   values=[\"SGD\", \"Adam\", \"Nadam\", \n",
    "#                                           \"Adamax\", \"RMSprop\"])\n",
    "\n",
    "#             model.compile(optimizer=optimizer_dict[optimizer], \n",
    "#                           loss=keras.losses.CategoricalCrossentropy(),\n",
    "#                           metrics=[keras.metrics.Accuracy(), \n",
    "#                                    keras.metrics.F1Score(),\n",
    "#                                    keras.metrics.Precision()])\n",
    "            \n",
    "#             return model\n",
    "        \n",
    "#         def fit(self, hp, model, *args, **kwargs):\n",
    "#               return model.fit(*args, \n",
    "#                                shuffle = hp.Boolean(\"shuffle\"),\n",
    "#                                **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_hypermodel(keras_tuner.HyperModel):\n",
    "        def build(self, hp):\n",
    "            lstm = models(num_class=num_class,\n",
    "                          vocab_size=vocab_size, \n",
    "                          embedding_seq_length=hp.Int(\"embedding_seq_length\", \n",
    "                                                      min_value=10, \n",
    "                                                      max_value=150, \n",
    "                                                      step=10))\n",
    "            \n",
    "            activations = [\"relu\", \"tanh\", \"sigmoid\",\n",
    "                           \"elu\", \"exponential\", \"selu\"]\n",
    "        \n",
    "            model = lstm.single_lstm(lstm_units=hp.Int(\"lstm_units\", min_value=25, \n",
    "                                                       max_value=200, step=5), \n",
    "                                     rate=hp.Float(\"rate\", min_value=0.2, \n",
    "                                                   max_value=0.7, step=0.025),\n",
    "                                     activation=hp.Choice(\"activation\", \n",
    "                                                          values=activations))\n",
    "\n",
    "            lr = hp.Float(\"learning_rate\", min_value=0.001, \n",
    "                          max_value=0.02, sampling=\"log\") \n",
    "            \n",
    "            optimizer_dict = {\n",
    "                  \"SGD\" : keras.optimizers.SGD(lr),\n",
    "                  \"Adam\" : keras.optimizers.Adam(lr),\n",
    "                  \"Nadam\" : keras.optimizers.Nadam(lr),\n",
    "                  \"Adamax\" : keras.optimizers.Adamax(lr),\n",
    "                  \"RMSprop\" : keras.optimizers.RMSprop(lr)\n",
    "            }\n",
    "\n",
    "            optimizer = hp.Choice(\"optimizer\", \n",
    "                                  values=[\"Adam\", \"SGD\", \"Nadam\", \n",
    "                                          \"Adamax\", \"RMSprop\"])\n",
    "\n",
    "            model.compile(optimizer=optimizer_dict[optimizer], \n",
    "                          loss=keras.losses.CategoricalCrossentropy(),\n",
    "                          metrics=[keras.metrics.Accuracy(), \n",
    "                                   keras.metrics.F1Score(),\n",
    "                                   keras.metrics.Precision()])\n",
    "            \n",
    "            return model\n",
    "        \n",
    "        def fit(self, hp, model, *args, **kwargs):\n",
    "              return model.fit(*args, \n",
    "                               shuffle = hp.Boolean(\"shuffle\", \n",
    "                                                    default=True),\n",
    "                               **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stacked_lstm_hypermodel(keras_tuner.HyperModel):\n",
    "        def build(self, hp):\n",
    "            lstm = models(num_class=num_class, \n",
    "                           vocab_size=vocab_size, \n",
    "                           embedding_seq_length=hp.Int(\"embedding_seq_length\", \n",
    "                                                       min_value=10, \n",
    "                                                       max_value=150, \n",
    "                                                       step=10))\n",
    "            \n",
    "            activations = [\"relu\", \"tanh\", \"sigmoid\",\n",
    "                           \"elu\", \"exponential\", \"selu\"]\n",
    "\n",
    "            model = lstm.stacked_lstm(lstm_units1=hp.Int(\"lstm_units1\", min_value=25, max_value=200, step=5),\n",
    "                                      lstm_units2=hp.Int(\"lstm_units2\", min_value=25, max_value=200, step=5),\n",
    "                                      rate1=hp.Float(\"rate1\", min_value=0.2, max_value=0.7, step=0.025),\n",
    "                                      rate2=hp.Float(\"rate2\", min_value=0.2, max_value=0.7, step=0.025), \n",
    "                                      activation=hp.Choice(\"activation\", values=activations))\n",
    "\n",
    "            lr = hp.Float(\"learning_rate\", min_value=0.001, \n",
    "                          max_value=0.02, sampling=\"log\")\n",
    "            \n",
    "            optimizer_dict = {\n",
    "                  \"SGD\" : keras.optimizers.SGD(lr),\n",
    "                  \"Adam\" : keras.optimizers.Adam(lr),\n",
    "                  \"Nadam\" : keras.optimizers.Nadam(lr),\n",
    "                  \"Adamax\" : keras.optimizers.Adamax(lr),\n",
    "                  \"RMSprop\" : keras.optimizers.RMSprop(lr)\n",
    "            }\n",
    "\n",
    "            optimizer = hp.Choice(\"optimizer\", \n",
    "                                  values=[\"Adam\", \"SGD\", \"Nadam\", \n",
    "                                          \"Adamax\", \"RMSprop\"])\n",
    "\n",
    "            model.compile(optimizer=optimizer_dict[optimizer], \n",
    "                          loss=keras.losses.CategoricalCrossentropy(),\n",
    "                          metrics=[keras.metrics.Accuracy(), \n",
    "                                   keras.metrics.F1Score(),\n",
    "                                   keras.metrics.Precision()])\n",
    "            \n",
    "            return model\n",
    "        \n",
    "        def fit(self, hp, model, *args, **kwargs):\n",
    "              return model.fit(*args, \n",
    "                               shuffle = hp.Boolean(\"shuffle\", \n",
    "                                                    default=True),\n",
    "                               **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convo_lstm_hypermodel(keras_tuner.HyperModel):\n",
    "        def build(self, hp):\n",
    "            lstm = models(num_class=num_class, \n",
    "                          vocab_size=vocab_size, \n",
    "                          embedding_seq_length=hp.Int(\"embedding_seq_length\", \n",
    "                                                      min_value=10, max_value=150, \n",
    "                                                      step=10))\n",
    "            \n",
    "            activations = [\"relu\", \"tanh\", \"sigmoid\",\n",
    "                           \"elu\", \"exponential\", \"selu\"]\n",
    "      \n",
    "            convo_units = hp.Int(\"convo_uints\", min_value=32, \n",
    "                                max_value=512, step=32)\n",
    "            kernal_size = hp.Int(\"kernal_size\", min_value=2, \n",
    "                                max_value=6, step=1)\n",
    "            convo_rate = hp.Float(\"convo_rate\", min_value=0.2, \n",
    "                                max_value=0.7, step=0.025)\n",
    "            convo_activaton = hp.Choice(\"convo_activation\", values=activations)\n",
    "            \n",
    "            lstm_units = hp.Int(\"lstm_units\", min_value=25, \n",
    "                                max_value=200, step=5)\n",
    "            lstm_rate = hp.Float(\"lstm_rate\", min_value=0.2, \n",
    "                                max_value=0.7, step=0.025)\n",
    "            lstm_activation = hp.Choice(\"lstm_activation\", values=activations)\n",
    "\n",
    "            model = lstm.convo_lstm(convo_units=convo_units, \n",
    "                                    kernal_size=kernal_size, \n",
    "                                    convo_rate=convo_rate,\n",
    "                                    convo_activaton=convo_activaton, \n",
    "                                    lstm_units=lstm_units, \n",
    "                                    lstm_rate=lstm_rate, \n",
    "                                    lstm_activation=lstm_activation)\n",
    "\n",
    "            lr = hp.Float(\"learning_rate\", min_value=0.001, \n",
    "                          max_value=0.02, sampling=\"log\")\n",
    "            \n",
    "            optimizer_dict = {\n",
    "                  \"SGD\" : keras.optimizers.SGD(lr),\n",
    "                  \"Adam\" : keras.optimizers.Adam(lr),\n",
    "                  \"Nadam\" : keras.optimizers.Nadam(lr),\n",
    "                  \"Adamax\" : keras.optimizers.Adamax(lr),\n",
    "                  \"RMSprop\" : keras.optimizers.RMSprop(lr)\n",
    "            }\n",
    "\n",
    "            optimizer = hp.Choice(\"optimizer\", \n",
    "                                  values=[\"Adam\", \"SGD\", \"Nadam\", \n",
    "                                          \"Adamax\", \"RMSprop\"])\n",
    "\n",
    "            model.compile(optimizer=optimizer_dict[optimizer], \n",
    "                          loss=keras.losses.CategoricalCrossentropy(),\n",
    "                          metrics=[keras.metrics.Accuracy(), \n",
    "                                   keras.metrics.F1Score(),\n",
    "                                   keras.metrics.Precision()])\n",
    "            \n",
    "            return model\n",
    "        \n",
    "        def fit(self, hp, model, *args, **kwargs):\n",
    "              return model.fit(*args, \n",
    "                               shuffle = hp.Boolean(\"shuffle\", default=True),\n",
    "                               **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = keras_tuner.HyperParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_lstm_tuner = keras_tuner.BayesianOptimization(lstm_hypermodel(),\n",
    "                                                     objective=\"val_accuracy\",\n",
    "                                                     max_trials=15,\n",
    "                                                     executions_per_trial=4,\n",
    "                                                     directory=\"lstm\", \n",
    "                                                     project_name=\"single_lstm_model\",\n",
    "                                                     overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "embedding_seq_length (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 150, 'step': 10, 'sampling': 'linear'}\n",
      "lstm_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 25, 'max_value': 200, 'step': 5, 'sampling': 'linear'}\n",
      "rate (Float)\n",
      "{'default': 0.2, 'conditions': [], 'min_value': 0.2, 'max_value': 0.7, 'step': 0.025, 'sampling': 'linear'}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid', 'elu', 'exponential', 'selu'], 'ordered': False}\n",
      "learning_rate (Float)\n",
      "{'default': 0.001, 'conditions': [], 'min_value': 0.001, 'max_value': 0.02, 'step': None, 'sampling': 'log'}\n",
      "optimizer (Choice)\n",
      "{'default': 'Adam', 'conditions': [], 'values': ['Adam', 'SGD', 'Nadam', 'Adamax', 'RMSprop'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "single_lstm_tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 10m 13s]\n",
      "val_accuracy: 0.0\n",
      "\n",
      "Best val_accuracy So Far: 0.0\n",
      "Total elapsed time: 00h 26m 17s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "50                |120               |embedding_seq_length\n",
      "25                |170               |lstm_units\n",
      "0.425             |0.625             |rate\n",
      "tanh              |exponential       |activation\n",
      "0.016296          |0.015908          |learning_rate\n",
      "Adam              |Adam              |optimizer\n",
      "True              |True              |shuffle\n",
      "\n",
      "Epoch 1/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.0000e+00 - f1_score: 0.0016 - loss: 4.4261 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 7.4185 - val_precision: 0.0000e+00\n",
      "Epoch 2/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - f1_score: 0.0013 - loss: 4.1447 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.0326 - val_precision: 0.0000e+00\n",
      "Epoch 3/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - f1_score: 0.0013 - loss: 4.1411 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.0742 - val_precision: 0.0000e+00\n",
      "Epoch 4/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.0000e+00 - f1_score: 0.0013 - loss: 4.1300 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.2594 - val_precision: 0.0000e+00\n",
      "Epoch 5/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.0000e+00 - f1_score: 0.0014 - loss: 4.1198 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 8.6168 - val_precision: 0.0000e+00\n",
      "Epoch 6/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.0000e+00 - f1_score: 0.0011 - loss: 4.1220 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.4373 - val_precision: 0.0000e+00\n",
      "Epoch 7/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - f1_score: 7.3180e-04 - loss: 4.1172 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.3616 - val_precision: 0.0000e+00\n",
      "Epoch 8/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - f1_score: 0.0017 - loss: 4.1114 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.5483 - val_precision: 0.0000e+00\n",
      "Epoch 9/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.0000e+00 - f1_score: 0.0010 - loss: 4.1142 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.7176 - val_precision: 0.0000e+00\n",
      "Epoch 10/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - f1_score: 0.0019 - loss: 4.1149 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.5285 - val_precision: 0.0000e+00\n",
      "Epoch 11/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 7.1449e-04 - loss: 4.1116 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.0374 - val_precision: 0.0000e+00\n",
      "Epoch 12/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - f1_score: 8.4047e-04 - loss: 4.1125 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.4288 - val_precision: 0.0000e+00\n",
      "Epoch 13/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - f1_score: 7.4430e-04 - loss: 4.1087 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 8.5391 - val_precision: 0.0000e+00\n",
      "Epoch 14/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - f1_score: 8.2825e-04 - loss: 4.1079 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.5256 - val_precision: 0.0000e+00\n",
      "Epoch 15/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - f1_score: 7.4331e-04 - loss: 4.1071 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.6445 - val_precision: 0.0000e+00\n",
      "Epoch 16/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - f1_score: 0.0013 - loss: 4.1058 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.9180 - val_precision: 0.0000e+00\n",
      "Epoch 17/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - f1_score: 8.5623e-04 - loss: 4.1075 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.5288 - val_precision: 0.0000e+00\n",
      "Epoch 18/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 0.0013 - loss: 4.1071 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.6774 - val_precision: 0.0000e+00\n",
      "Epoch 19/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - f1_score: 0.0014 - loss: 4.1065 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.5353 - val_precision: 0.0000e+00\n",
      "Epoch 20/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.0000e+00 - f1_score: 0.0011 - loss: 4.1043 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.9390 - val_precision: 0.0000e+00\n",
      "Epoch 21/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - f1_score: 0.0015 - loss: 4.1041 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 8.9967 - val_precision: 0.0000e+00\n",
      "Epoch 22/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 0.0014 - loss: 4.1040 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.9798 - val_precision: 0.0000e+00\n",
      "Epoch 23/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 7.0517e-04 - loss: 4.1047 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.8519 - val_precision: 0.0000e+00\n",
      "Epoch 24/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 9.8276e-04 - loss: 4.1055 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.9106 - val_precision: 0.0000e+00\n",
      "Epoch 25/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 7.2297e-04 - loss: 4.1044 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.5989 - val_precision: 0.0000e+00\n",
      "Epoch 26/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 0.0020 - loss: 4.1021 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 8.8548 - val_precision: 0.0000e+00\n",
      "Epoch 27/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - f1_score: 0.0012 - loss: 4.1045 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 9.0563 - val_precision: 0.0000e+00\n",
      "Epoch 28/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 8.5776e-04 - loss: 4.1043 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.9760 - val_precision: 0.0000e+00\n",
      "Epoch 29/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 8.4438e-04 - loss: 4.1023 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 9.3408 - val_precision: 0.0000e+00\n",
      "Epoch 30/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 0.0014 - loss: 4.1040 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 9.4481 - val_precision: 0.0000e+00\n",
      "Epoch 1/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - accuracy: 0.0000e+00 - f1_score: 0.0029 - loss: 4.4334 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 7.4442 - val_precision: 0.0000e+00\n",
      "Epoch 2/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - f1_score: 0.0013 - loss: 4.1485 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 7.9418 - val_precision: 0.0000e+00\n",
      "Epoch 3/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - f1_score: 0.0012 - loss: 4.1294 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 8.0808 - val_precision: 0.0000e+00\n",
      "Epoch 4/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - f1_score: 0.0010 - loss: 4.1243 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 7.9630 - val_precision: 0.0000e+00\n",
      "Epoch 5/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 8.8581e-04 - loss: 4.1243 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.5533 - val_precision: 0.0000e+00\n",
      "Epoch 6/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.0000e+00 - f1_score: 0.0016 - loss: 4.1152 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.2339 - val_precision: 0.0000e+00\n",
      "Epoch 7/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 0.0011 - loss: 4.1162 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.4318 - val_precision: 0.0000e+00\n",
      "Epoch 8/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - f1_score: 6.7445e-04 - loss: 4.1146 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.3681 - val_precision: 0.0000e+00\n",
      "Epoch 9/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 0.0011 - loss: 4.1148 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.3697 - val_precision: 0.0000e+00\n",
      "Epoch 10/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 0.0015 - loss: 4.1146 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 9.1190 - val_precision: 0.0000e+00\n",
      "Epoch 11/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 0.0011 - loss: 4.1112 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.8491 - val_precision: 0.0000e+00\n",
      "Epoch 12/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 9.7051e-04 - loss: 4.1117 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.8584 - val_precision: 0.0000e+00\n",
      "Epoch 13/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 0.0015 - loss: 4.1112 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.7610 - val_precision: 0.0000e+00\n",
      "Epoch 14/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - f1_score: 7.4784e-04 - loss: 4.1085 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 9.0141 - val_precision: 0.0000e+00\n",
      "Epoch 15/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 6.1102e-04 - loss: 4.1049 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.8489 - val_precision: 0.0000e+00\n",
      "Epoch 16/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 8.1554e-04 - loss: 4.1059 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.8428 - val_precision: 0.0000e+00\n",
      "Epoch 17/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 8.4292e-04 - loss: 4.1059 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 9.3150 - val_precision: 0.0000e+00\n",
      "Epoch 18/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - f1_score: 7.4567e-04 - loss: 4.1050 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.6451 - val_precision: 0.0000e+00\n",
      "Epoch 19/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - f1_score: 9.8162e-04 - loss: 4.1059 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.6419 - val_precision: 0.0000e+00\n",
      "Epoch 20/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - f1_score: 0.0011 - loss: 4.1043 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.7324 - val_precision: 0.0000e+00\n",
      "Epoch 21/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - f1_score: 0.0012 - loss: 4.1050 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 9.0528 - val_precision: 0.0000e+00\n",
      "Epoch 22/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 0.0011 - loss: 4.1032 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 9.2807 - val_precision: 0.0000e+00\n",
      "Epoch 23/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.0000e+00 - f1_score: 5.6568e-04 - loss: 4.1054 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.8749 - val_precision: 0.0000e+00\n",
      "Epoch 24/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - f1_score: 8.9309e-04 - loss: 4.1046 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.5250 - val_precision: 0.0000e+00\n",
      "Epoch 25/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 8.7833e-04 - loss: 4.1031 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 9.3284 - val_precision: 0.0000e+00\n",
      "Epoch 26/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 0.0012 - loss: 4.1042 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.9165 - val_precision: 0.0000e+00\n",
      "Epoch 27/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 6.2868e-04 - loss: 4.1032 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 9.4176 - val_precision: 0.0000e+00\n",
      "Epoch 28/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 0.0016 - loss: 4.1039 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 9.7511 - val_precision: 0.0000e+00\n",
      "Epoch 29/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 5.9298e-04 - loss: 4.1021 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 10.1600 - val_precision: 0.0000e+00\n",
      "Epoch 30/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - f1_score: 6.0010e-04 - loss: 4.1021 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 9.3746 - val_precision: 0.0000e+00\n",
      "Epoch 1/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - accuracy: 0.0000e+00 - f1_score: 0.0016 - loss: 4.4173 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 7.8439 - val_precision: 0.0000e+00\n",
      "Epoch 2/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 0.0014 - loss: 4.1337 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 7.6556 - val_precision: 0.0000e+00\n",
      "Epoch 3/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 0.0011 - loss: 4.1340 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.0772 - val_precision: 0.0000e+00\n",
      "Epoch 4/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - f1_score: 7.2530e-04 - loss: 4.1260 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 7.7695 - val_precision: 0.0000e+00\n",
      "Epoch 5/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 0.0011 - loss: 4.1219 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.3369 - val_precision: 0.0000e+00\n",
      "Epoch 6/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - f1_score: 0.0014 - loss: 4.1186 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 8.3393 - val_precision: 0.0000e+00\n",
      "Epoch 7/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 0.0016 - loss: 4.1181 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.3919 - val_precision: 0.0000e+00\n",
      "Epoch 8/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - f1_score: 0.0018 - loss: 4.1199 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.6863 - val_precision: 0.0000e+00\n",
      "Epoch 9/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 0.0019 - loss: 4.1136 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 8.0364 - val_precision: 0.0000e+00\n",
      "Epoch 10/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 6.0112e-04 - loss: 4.1149 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 8.4413 - val_precision: 0.0000e+00\n",
      "Epoch 11/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 0.0011 - loss: 4.1129 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.3590 - val_precision: 0.0000e+00\n",
      "Epoch 12/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 0.0013 - loss: 4.1115 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.3095 - val_precision: 0.0000e+00\n",
      "Epoch 13/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 4.6699e-04 - loss: 4.1106 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.4238 - val_precision: 0.0000e+00\n",
      "Epoch 14/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - f1_score: 0.0012 - loss: 4.1082 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.7059 - val_precision: 0.0000e+00\n",
      "Epoch 15/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - f1_score: 0.0013 - loss: 4.1093 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 8.8700 - val_precision: 0.0000e+00\n",
      "Epoch 16/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 9.2691e-04 - loss: 4.1074 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.6596 - val_precision: 0.0000e+00\n",
      "Epoch 17/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - f1_score: 7.6453e-04 - loss: 4.1104 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.9970 - val_precision: 0.0000e+00\n",
      "Epoch 18/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - f1_score: 8.7059e-04 - loss: 4.1058 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 9.1025 - val_precision: 0.0000e+00\n",
      "Epoch 19/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - f1_score: 9.2506e-04 - loss: 4.1052 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.7418 - val_precision: 0.0000e+00\n",
      "Epoch 20/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - f1_score: 6.5387e-04 - loss: 4.1068 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.7992 - val_precision: 0.0000e+00\n",
      "Epoch 21/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - f1_score: 5.8318e-04 - loss: 4.1038 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.6595 - val_precision: 0.0000e+00\n",
      "Epoch 22/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.0000e+00 - f1_score: 6.0945e-04 - loss: 4.1062 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 9.1042 - val_precision: 0.0000e+00\n",
      "Epoch 23/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 6.5429e-04 - loss: 4.1063 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 9.1337 - val_precision: 0.0000e+00\n",
      "Epoch 24/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - f1_score: 7.9730e-04 - loss: 4.1041 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 9.1697 - val_precision: 0.0000e+00\n",
      "Epoch 25/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 8.5385e-04 - loss: 4.1049 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 9.0548 - val_precision: 0.0000e+00\n",
      "Epoch 26/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - f1_score: 7.6507e-04 - loss: 4.1013 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.7527 - val_precision: 0.0000e+00\n",
      "Epoch 27/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 0.0010 - loss: 4.1024 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 9.0902 - val_precision: 0.0000e+00\n",
      "Epoch 28/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - f1_score: 0.0013 - loss: 4.1026 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.7771 - val_precision: 0.0000e+00\n",
      "Epoch 29/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - f1_score: 6.2907e-04 - loss: 4.1024 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 8.9276 - val_precision: 0.0000e+00\n",
      "Epoch 30/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 7.3249e-04 - loss: 4.1035 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.8136 - val_precision: 0.0000e+00\n",
      "Epoch 1/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - accuracy: 0.0000e+00 - f1_score: 0.0023 - loss: 4.4301 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 7.6476 - val_precision: 0.0000e+00\n",
      "Epoch 2/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - f1_score: 8.6289e-04 - loss: 4.1438 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 7.9822 - val_precision: 0.0000e+00\n",
      "Epoch 3/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - f1_score: 0.0010 - loss: 4.1366 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 7.9559 - val_precision: 0.0000e+00\n",
      "Epoch 4/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - f1_score: 0.0013 - loss: 4.1219 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 3.2520e-04 - val_loss: 8.3063 - val_precision: 0.0000e+00\n",
      "Epoch 5/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - f1_score: 7.9118e-04 - loss: 4.1214 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.6073 - val_precision: 0.0000e+00\n",
      "Epoch 6/30\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 0.0012 - loss: 4.1189 - precision: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_loss: 8.3075 - val_precision: 0.0000e+00\n",
      "Epoch 7/30\n",
      "\u001b[1m81/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - f1_score: 8.1744e-04 - loss: 4.1166 - precision: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "single_lstm_tuner.search(x_train.iloc[:3000], y_train[:3000, :], epochs=30, validation_data=(x_val.iloc[:800], y_val[:800, ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune(model_name, trials=15, pre_trials=4):\n",
    "    if model_name == \"single_lstm\":\n",
    "        print(\"[INFO] Hyperparameter Tuning for Single LSTM...\")\n",
    "        hypermodel = lstm_hypermodel()\n",
    "        directory = \"lstm\"\n",
    "        project_name=\"single_lstm_model\"\n",
    "    \n",
    "    elif model_name == \"stacked_lstm\":\n",
    "        print(\"[INFO] Hyperparameter Tuning for Stacked LSTM...\")\n",
    "        hypermodel = stacked_lstm_hypermodel()\n",
    "        directory = \"lstm\"\n",
    "        project_name = \"stacked_lstm_model\"\n",
    "\n",
    "    elif model_name == \"convo_lstm\":\n",
    "        print(\"[INFO] Hyperparameter Tuning for Convo-LSTM...\")\n",
    "        hypermodel = convo_lstm_hypermodel()\n",
    "        directory = \"lstm\"\n",
    "        project_name = \"convo_lstm_model\"\n",
    "\n",
    "    tuner = keras_tuner.BayesianOptimization(hypermodel= hypermodel,\n",
    "                                             objective=\"val_accuracy\",\n",
    "                                             max_trials=trials,\n",
    "                                             executions_per_trial=pre_trials,\n",
    "                                             directory=directory, \n",
    "                                             project_name=project_name,\n",
    "                                             overwrite=True)\n",
    "    print(\"\\t[INFO] Hyperparameter Search Space\\n\", tuner.search_space_summary())     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
