{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7PAM2002-0901-2024 - MSc Data Science Project\n",
    "\n",
    "Topic - Comparing Data Augmentation Methods â€“ Easy Data Augmentation and Back Translation for text(Intentation) Classification using LSTM.\n",
    "\n",
    "Research Question - Which data augmentation methods applied on a small dataset outperform models trained without augmentation in terms of accuracy and precision in case of intention(text) classification using LSTM as training models, and by how much do they improve performance?\n",
    "\n",
    "Supervisor - Dr. Man Lai Tang\n",
    "\n",
    "Done by - Mohit Agarwal (22031257)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required packages...\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending the location for augment modules\n",
    "import sys\n",
    "sys.path.append(r\"D:\\MScDataScience\\7.Data_Science_Project\\SourceCode\\Agument\")\n",
    "# appending the location for modles modules\n",
    "sys.path.append(r\"D:\\MScDataScience\\7.Data_Science_Project\\SourceCode\\Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\agarw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importing modules from local drives...\n",
    "import preprocess_eda as preprocess\n",
    "import lstm\n",
    "import train_lstm\n",
    "import back_translation\n",
    "import eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setiing plot style\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for augment plot\n",
    "augment_plot_path = r\"D:\\MScDataScience\\7.Data_Science_Project\\SourceCode\\Plots\\Augment\"\n",
    "# path for augment data\n",
    "augment_data_path = r\"D:\\MScDataScience\\7.Data_Science_Project\\SourceCode\\Agument\\Augment_Data\\Training_Validation_Testing\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the training, validation, testin data for augmentation\n",
    "whole_data = pd.concat([preprocess.train_df,\n",
    "                        preprocess.val_df,\n",
    "                        preprocess.test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EDA Data Augmented from Whole Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading size 1 data\n",
    "eda_size_1_train, eda_size_1_val, eda_size_1_test = preprocess.load_augment(\n",
    "    os.path.join(augment_data_path, r\"EDA\\eda_augmented_data_size_1.csv\"), data=whole_data)\n",
    "# reading size 2 data\n",
    "eda_size_2_train, eda_size_2_val, eda_size_2_test = preprocess.load_augment(\n",
    "    os.path.join(augment_data_path, r\"EDA\\eda_augmented_data_size_2.csv\"), data=whole_data)\n",
    "# reading size 3 data\n",
    "eda_size_3_train, eda_size_3_val, eda_size_3_test = preprocess.load_augment(\n",
    "    os.path.join(augment_data_path, r\"EDA\\eda_augmented_data_size_3.csv\"), data=whole_data)\n",
    "# reading size 4 data\n",
    "eda_size_4_train, eda_size_4_val, eda_size_4_test = preprocess.load_augment(\n",
    "    os.path.join(augment_data_path, r\"EDA\\eda_augmented_data_size_4.csv\"), data=whole_data)\n",
    "# reading size 5 data\n",
    "eda_size_5_train, eda_size_5_val, eda_size_5_test = preprocess.load_augment(\n",
    "    os.path.join(augment_data_path, r\"EDA\\eda_augmented_data_size_5.csv\"), data=whole_data)\n",
    "# reading size 10 data\n",
    "eda_size_10_train, eda_size_10_val, eda_size_10_test = preprocess.load_augment(\n",
    "    os.path.join(augment_data_path, r\"EDA\\eda_augmented_data_size_10.csv\"), data=whole_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Augmented Data Through EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Size-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
